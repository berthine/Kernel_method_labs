{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Session 2\n",
    "### Kernel Methods for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Yunlong Jiao / Romain Menegaux, 19 May 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Aug 13 2019, 20:35:49) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model as lm\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement (naive) solvers to Ridge Regression, Weighted Ridge Regression and Logistic Ridge Regression (using Iteratively Reweighted Least Squares). See notes for the mathematical derivation.\n",
    "2. Simulate some toy data to check if our solvers give correct solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "p = 10\n",
    "X = np.random.normal(0, 1, (n, p))\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "beta_star = np.random.normal(0, 1, p)\n",
    "y = X.dot(beta_star) + 0.2 * np.random.normal(0, 1, n)\n",
    "\n",
    "def compare(beta1, beta2):\n",
    "    print('''\n",
    "Our solver:\n",
    "{}\n",
    "Scikit-learn:\n",
    "{}\n",
    "\n",
    "Difference between the two:\n",
    "{}\n",
    "        '''.format(beta1, beta2, np.sum((beta1-beta2)**2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def solveRR(y, X, lam):\n",
    "# n, p = X.shape\n",
    "# assert (len(y) == n)\n",
    "\n",
    "# A = X.T.dot(X)\n",
    "# # Adjust diagonal due to Ridge\n",
    "# A[np.diag_indices_from(A)] += lam * n\n",
    "# b = X.T.dot(y)\n",
    "\n",
    "# # Hint:\n",
    "# beta = np.linalg.solve(A, b)\n",
    "# # Finds solution to the linear system Ax = b\n",
    "# return (beta) \n",
    "# # Weighted Ridge Regression (WRR)\n",
    "# def solveWRR(y, X, w, lam):\n",
    "# n, p = X.shape\n",
    "# assert (len(y) == len(w) == n)\n",
    "\n",
    "# y1 = np.sqrt(w) * y\n",
    "# X1 = (np.sqrt(w) * X.T).T\n",
    "# # Hint:\n",
    "# # Find y1 and X1 such that:\n",
    "# beta = solveRR(y1, X1, lam)\n",
    "# return (beta) \n",
    "\n",
    "\n",
    "# Logistic Ridge Regression (LRR)\n",
    "# def solveLRR(y, X, lam):\n",
    "# n, p = X.shape\n",
    "# assert (len(y) == n)\n",
    "\n",
    "# # Parameters\n",
    "# max_iter = 100\n",
    "# eps = 1e-3\n",
    "# sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "\n",
    "# # Initialize\n",
    "# beta = np.zeros(p)\n",
    "\n",
    "# # Hint: Use IRLS\n",
    "# for i in range(max_iter):\n",
    "# beta_old = beta\n",
    "# f = X.dot(beta_old)\n",
    "# w = sigmoid(f) * sigmoid(-f)\n",
    "# z = f + y / sigmoid(y*f)\n",
    "# beta = solveWRR(z, X, w, 2*lam)\n",
    "# # Break condition (achieved convergence)\n",
    "# if np.sum((beta-beta_old)**2) < eps:\n",
    "# break\n",
    "# return (beta) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regression (RR)**\n",
    "\n",
    "Given $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\mathbb{R}^n$, solve\n",
    "$$\n",
    "\\min_{\\beta \\in \\mathbb{R}^p} \\frac{1}{n} \\|y - X \\beta\\|^2 + \\lambda \\|\\beta\\|^2 \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression (RR)\n",
    "def solveRR(y, X, lam):\n",
    "    n, p = X.shape\n",
    "    assert (len(y) == n)\n",
    "    A = X.T.dot(X)\n",
    "    #adjust diagonal due to ridge\n",
    "    A[np.diag_indices_from(A)] += lam*n\n",
    "    b =X.T.dot(y)\n",
    "    # Hint:\n",
    "    beta = np.linalg.solve(A, b)\n",
    "    # Finds solution to the linear system Ax = b\n",
    "    \n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it out:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our solver:\n",
      "[ 1.27929172  0.78935356  0.05064497 -0.55474398  0.65276533  0.32637554\n",
      "  0.765293    0.63326617  0.97285396 -0.5294559 ]\n",
      "Scikit-learn:\n",
      "[ 1.27929172  0.78935356  0.05064497 -0.55474398  0.65276533  0.32637554\n",
      "  0.765293    0.63326617  0.97285396 -0.5294559 ]\n",
      "\n",
      "Difference between the two:\n",
      "1.9841893252049497e-31\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "lam = 0.1\n",
    "\n",
    "# Our solver\n",
    "beta1 = solveRR(y, X, lam)\n",
    "\n",
    "# Python solver\n",
    "alpha = lam * X.shape[0]\n",
    "model = lm.Ridge(alpha=alpha, fit_intercept=False, normalize=False)\n",
    "beta2 = model.fit(X, y).coef_\n",
    "\n",
    "# Check\n",
    "compare(beta1, beta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Ridge Regression (WRR)**\n",
    "\n",
    "Given $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\mathbb{R}^n$, and weights $w \\in \\mathbb{R}^n_+$, solve\n",
    "$$\n",
    "\\min_{\\beta \\in \\mathbb{R}^p} \\frac{1}{n} \\sum_{i=1}^n w_i (y_i - \\beta^\\top x_i)^2 + \\lambda \\|\\beta\\|^2 \\,.\n",
    "$$\n",
    "Think of $w_i$ as important or confidence you have in poit $i$.\n",
    "\n",
    "\n",
    "**Goal:** Express the objective as a regular Ridge Regression (RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Ridge Regression (WRR)\n",
    "def solveWRR(y, X, w, lam):\n",
    "    n, p = X.shape\n",
    "    assert (len(y) == len(w) == n)\n",
    "#     w = np.diag(w)\n",
    "    y1 = np.sqrt(w)*y\n",
    "    X1 = (np.sqrt(w)* X.T).T\n",
    "    \n",
    "\n",
    "    # Hint:\n",
    "    # Find y1 and X1 such that:\n",
    "    beta = solveRR(y1, X1, lam)\n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it out:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our solver:\n",
      "[ 1.21907902  0.69464471  0.05119819 -0.50155617  0.60130538  0.2718474\n",
      "  0.6571524   0.60033163  0.862139   -0.50913719]\n",
      "Scikit-learn:\n",
      "[ 1.21907902  0.69464471  0.05119819 -0.50155617  0.60130538  0.2718474\n",
      "  0.6571524   0.60033163  0.862139   -0.50913719]\n",
      "\n",
      "Difference between the two:\n",
      "3.081969393505674e-31\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "lam = 0.1\n",
    "w = np.random.rand(len(y))\n",
    "\n",
    "# Our solver\n",
    "beta1 = solveWRR(y, X, w, lam)\n",
    "\n",
    "# Python solver\n",
    "alpha = lam * X.shape[0]\n",
    "model = lm.Ridge(alpha=alpha, fit_intercept=False, normalize=False)\n",
    "beta2 = model.fit(X, y, sample_weight=w).coef_\n",
    "\n",
    "# Check\n",
    "compare(beta1, beta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Ridge Regression (LRR)**\n",
    "\n",
    "Given $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\{-1,+1\\}^n$, solve\n",
    "$$\n",
    "\\min_{\\beta \\in \\mathbb{R}^p} \\frac{1}{n} \\sum_{i=1}^n \\log (1+e^{-y_i \\beta^\\top x_i}) + \\lambda \\|\\beta\\|^2 \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ be the sigmoid function.\n",
    "\n",
    "Compute $\\sigma'(x) = \\frac{e^{-x}}{(1+ e^{-x})^2}=\\sigma(x) (1-\\sigma(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewriting $J$:\n",
    "$$\n",
    "J(\\beta) = - \\frac{1}{n} \\sum_{i=1}^n {\\log(\\sigma(y_i\\beta^\\top x_i))} + 2\\lambda \\beta \\,.\n",
    "$$\n",
    "\n",
    "Compute its gradient $\\nabla J$, and its Hessian $\\nabla^2 J$\n",
    "$$$$\n",
    "**Computing the gradien**:\n",
    "\n",
    "$\\nabla J (\\beta) = \\frac{- 1}{n}\\sum(y_i) \\sigma(-y_i\\beta^T x_i)x_i + 2 \\lambda \\beta $\n",
    "\n",
    "**Hessian matrix**:\n",
    "\n",
    "$\\nabla ^2 J(\\beta)= \\nabla (\\nabla J(\\beta))$\n",
    "$$$$\n",
    "$ \\nabla ^2 J(\\beta) =\\frac{-1}{n}X^T WX + 2 \\lambda I$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solving for optimal $\\beta$ using Newton-Raphson\n",
    "$$\n",
    "\\beta^{new} \\leftarrow \\beta^{old} - \\left(\\nabla^2 J(\\beta^{old})\\right)^{-1} \\nabla J(\\beta^{old})\n",
    "$$ \n",
    "This agoritm converge to the optimal $\\beta$\n",
    "\n",
    "$\\approx$ gradient descent with adapted step size.\n",
    "\n",
    "\n",
    "Show that each step is equivalent to solving a weighted ridge regression (WRR). Hence we can compute $\\beta$ without the Hessian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>Quadratic approximation to $J$</font>:\n",
    "\n",
    "$$\n",
    "J(\\beta) \\approx J_q(\\beta) = J(\\beta^{old}) + (\\beta - \\beta^{old})^\\top \\nabla J(\\beta^{old}) + \\frac{1}{2} (\\beta - \\beta^{old})^\\top \\nabla^2 J(\\beta^{old}) (\\beta - \\beta^{old})\n",
    "$$\n",
    "\n",
    "**lemma**: $\\min_\\beta J_q(\\beta) = \\beta^{new}$\n",
    "\n",
    "*proof*: we know that $\\beta ^{new} = \\beta^{old} - \\left(\\nabla^2 J(\\beta^{old})\\right)^{-1} \\nabla J(\\beta^{old})$\n",
    "\n",
    "So $\\nabla J_q (\\beta) = \\nabla J(\\beta^{old}) + \\nabla^{2}J(\\beta^{old})(\\beta - \\beta^{old})   $\n",
    "\n",
    "$\\nabla J_q (\\beta)=0 \\iff \\nabla J(\\beta^{old}) + \\nabla^{2}J(\\beta^{old})(\\beta - \\beta^{old}) =0 $\n",
    "$\\iff \\beta = \\beta^{old} - (\\nabla^{2}J(\\beta^{old}))^{-1} \\nabla J (\\beta^{old})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next **show that $J_q$ is a WRR objective**\n",
    "Let us write   $J_q$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sigmoid =lambda a: 1/(1+np.exp(-a))\n",
    "sigmoid(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Ridge Regression (LRR)\n",
    "def solveLRR(y, X, lam):\n",
    "    n, p = X.shape\n",
    "    assert (len(y) == n)\n",
    "    #beta_old = 0.001\n",
    "    \n",
    "    #parameters\n",
    "    max_iter = 100\n",
    "    eps = 1e-3\n",
    "    sigmoid = lambda a: 1/(1+np.exp(-a))\n",
    "    \n",
    "    #initialization\n",
    "    beta= np.zeros(p)\n",
    "       \n",
    "            \n",
    "    # Hint: Use IRLS\n",
    "    for i in range(max_iter):\n",
    "    #     ...\n",
    "        beta_old = beta \n",
    "        f = X.dot(beta_old)\n",
    "        w = (sigmoid(f)*sigmoid(-f))\n",
    "        z = f + y/sigmoid(y*f)\n",
    "#         print(X.shape, z.shape, w.shape)\n",
    "        beta = solveWRR(z, X, w, 2*lam)\n",
    "    #break condition\n",
    "        if np.sum((beta - beta_old)**2) <eps:\n",
    "            break\n",
    "\n",
    "#     if (some condition)\n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it out:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our solver:\n",
      "[ 0.49767127  0.31536865 -0.08695284 -0.16928256  0.27290418  0.15201934\n",
      "  0.35505561  0.31972318  0.30170835 -0.39445233]\n",
      "Scikit-learn:\n",
      "[[ 0.49767184  0.31536829 -0.08695313 -0.16928249  0.2729044   0.15201826\n",
      "   0.3550554   0.31972255  0.30170796 -0.39445232]]\n",
      "\n",
      "Difference between the two:\n",
      "2.3618668897770345e-12\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "y_bin = np.sign(y) # Binarize targets\n",
    "lam = 0.1\n",
    "\n",
    "# Our solver\n",
    "beta1 = solveLRR(y_bin, X, lam)\n",
    "\n",
    "# Python solver\n",
    "alpha = 2 * lam * X.shape[0]\n",
    "model = lm.LogisticRegression(C=1/alpha, fit_intercept=False)\n",
    "beta2 = model.fit(X, y_bin).coef_\n",
    "\n",
    "# Check\n",
    "compare(beta1, beta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Data Challenge\n",
    "\n",
    "We will try to predict whether patients have breast cancer.\n",
    "\n",
    "We use scikit-learn's [breast cancer dataset](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset)\n",
    "\n",
    "30 features, 569 samples, 2 labels ('malignant' or 'benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and split into training / validation sets\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.16286735e-15, -6.53060890e-15, -7.07889127e-16, -8.79983452e-16,\n",
       "        6.13217737e-15, -1.12036918e-15, -4.42138027e-16,  9.73249991e-16,\n",
       "       -1.97167024e-15, -1.45363120e-15, -9.07641468e-16, -8.85349205e-16,\n",
       "        1.77367396e-15, -8.29155139e-16, -7.54180940e-16, -3.92187747e-16,\n",
       "        7.91789988e-16, -2.73946068e-16, -3.10823423e-16, -3.36676596e-16,\n",
       "       -2.33322442e-15,  1.76367415e-15, -1.19802625e-15,  5.04966114e-16,\n",
       "       -5.21317026e-15, -2.17478837e-15,  6.85645643e-16, -1.41265636e-16,\n",
       "       -2.28956670e-15,  2.57517109e-15])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our model and compute its parameters\n",
    "lam = 0.01\n",
    "beta = solveLRR(y_train, X_train, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities and classes\n",
    "sigmoid  = lambda a: 1/(1+np.exp(-a))\n",
    "pred = beta.T.dot(X_test.T)\n",
    "probas_pred = sigmoid(pred)\n",
    "y_pred = np.round(probas_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model's performance:\n",
      "Accuracy: 97.87%\n",
      "AUC: 99.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "print(\"Our model's performance:\")\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('AUC: {:.2%}'.format(roc_auc_score(y_test, probas_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        67\n",
      "           1       0.99      0.98      0.98       121\n",
      "\n",
      "    accuracy                           0.98       188\n",
      "   macro avg       0.97      0.98      0.98       188\n",
      "weighted avg       0.98      0.98      0.98       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bqplot.pyplot as plt\n",
    "# from bqplot import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eedebf5fb04dd0b0e940deb6516b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(scale=LinearScale()), Axis(orientation='vertical', scale=LinearScale())], fig…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(title = 'feature importances')\n",
    "plt.bar(np.arange(len(beta)), beta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909279feb7914719bafaa2c956087515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(scale=LinearScale()), Axis(grid_lines='dashed', orientation='vertical', scale…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "n = 200\n",
    "x = np.linspace(0.0, 10.0, n)\n",
    "y = np.cumsum(np.random.randn(n))\n",
    "plt.plot(x,y, axes_options={'y': {'grid_lines': 'dashed'}})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
